_set_auto_parallel_context_func_map:
    "search_mode": auto_parallel_context().set_strategy_search_mode,
    "auto_parallel_search_mode": auto_parallel_context().set_auto_parallel_search_mode,


D:\Desktop\works\coderead\mindspore\mindspore\tests\ut\python\parallel\test_auto_parallel_pangu_alpha.py:
stras = _cell_graph_executor._get_shard_strategy(model._train_network)


可能得一些函数：
StepAutoParallel

重排布代价

代价

 *  example2:
 *    in_device_arrangement = [8, 4],
 *    in_tensor_map = [0, 1],
 *    in_tensor_shape = [512, 1024],
 *    out_device_arrangement = [4, 2, 2, 2]
 *  =>
 *    out_tensor_map = [1, 0, 3, 2],
 *    out_tensor_shape = [2, 256, 4, 256]

 关键数据结构：
 tensor_map：

device_arrangement:

tensor_layout:由device_arrangement，tensor_map和tensor_shape组成

DeviceMatrix:
// 和tensor_map的关系，反着的
// tensor_map_.GetDimByIdx(idx) should not be -1
int64_t TensorLayout::GetSliceDeviceDimensionByTensorDimensionIndex(uint64_t idx) const {
  return static_cast<int64_t>(device_arrangement_.GetDimSize()) - 1 - tensor_map_.GetDimByIdx(idx);
}
在分布式计算中，张量的物理布局（即设备上的实际存储方式）通常与逻辑布局（即程序员定义的张量映射）是相反的。这意味着，如果我们在逻辑上将一个维度映射到设备的第一个维度，那么在物理上，这个维度可能实际上是存储在最后一个维度上的。因此，函数中的减法操作实际上是在进行这种逻辑到物理的转换。
具体来说，device_arrangement_.GetDimSize()返回设备布局的总维度数，而tensor_map_.GetDimByIdx(idx)返回张量映射中给定索引的维度值。函数通过从设备布局的总维度数减去1（因为索引是从0开始的），然后再减去张量映射的维度值，来得到对应的设备切片维度。

node类型：
