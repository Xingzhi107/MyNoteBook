åœ¨MoEæ··åˆä¸“å®¶ä¸­ï¼Œçƒ­é—¨ä¸“å®¶æ”¾åœ¨æœ¬åœ°çš„ä¸“å®¶æ“ä½œæ˜¯ä¸€ç§ä¼˜åŒ–ç­–ç•¥ï¼Œå®ƒå¯ä»¥å‡å°‘é€šä¿¡å¼€é”€å’Œå»¶è¿Ÿï¼Œæé«˜æ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒçš„åšæ³•æ˜¯ï¼š

é¦–å…ˆï¼Œæ ¹æ®æ•°æ®çš„åˆ†å¸ƒå’Œä»»åŠ¡çš„ç‰¹ç‚¹ï¼Œé¢„å…ˆç¡®å®šä¸€äº›çƒ­é—¨ä¸“å®¶ï¼Œä¹Ÿå°±æ˜¯è¢«é¢‘ç¹é€‰æ‹©çš„ä¸“å®¶ï¼Œè¿™äº›ä¸“å®¶é€šå¸¸å…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§å’Œé€‚åº”æ€§ï¼Œå¯ä»¥å¤„ç†å¤šç§ç±»å‹çš„è¾“å…¥æ•°æ®ã€‚
ç„¶åï¼Œå°†è¿™äº›çƒ­é—¨ä¸“å®¶å¤åˆ¶åˆ°æ¯ä¸ªæœ¬åœ°è®¾å¤‡ä¸Šï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªè®­ç»ƒæˆ–æ¨ç†çš„å·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œè¿™æ ·æ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥ç›´æ¥è®¿é—®è¿™äº›ä¸“å®¶ï¼Œè€Œä¸éœ€è¦é€šè¿‡ç½‘ç»œé€šä¿¡ã€‚
æœ€åï¼Œå½“è¾“å…¥æ•°æ®åˆ°è¾¾æŸä¸ªèŠ‚ç‚¹æ—¶ï¼Œä½¿ç”¨é—¨æ§ç½‘ç»œæ¥é€‰æ‹©åˆé€‚çš„ä¸“å®¶ï¼Œå¦‚æœé€‰æ‹©çš„ä¸“å®¶æ˜¯æœ¬åœ°çš„çƒ­é—¨ä¸“å®¶ï¼Œé‚£ä¹ˆç›´æ¥ä½¿ç”¨æœ¬åœ°çš„å‰¯æœ¬è¿›è¡Œå¤„ç†ï¼Œå¦‚æœé€‰æ‹©çš„ä¸“å®¶æ˜¯è¿œç¨‹çš„éçƒ­é—¨ä¸“å®¶ï¼Œé‚£ä¹ˆé€šè¿‡ç½‘ç»œé€šä¿¡æ¥è·å–ä¸“å®¶çš„è¾“å‡ºã€‚
è¿™ç§æ“ä½œçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥å‡å°‘å¯¹è¿œç¨‹ä¸“å®¶çš„ä¾èµ–ï¼Œé™ä½ç½‘ç»œä¼ è¾“çš„æ•°æ®é‡å’Œæ—¶é—´ï¼Œæé«˜æ¨¡å‹çš„å¹¶è¡Œåº¦å’Œååé‡ã€‚åŒæ—¶ï¼Œä¹Ÿå¯ä»¥ä¿ç•™ä¸“å®¶çš„å¤šæ ·æ€§å’Œä¸“ä¸šæ€§ï¼Œé¿å…æ¨¡å‹è¿‡äºé›†ä¸­åœ¨å°‘æ•°ä¸“å®¶ä¸Šï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚

è¿™ç§æ“ä½œçš„ä¸€ä¸ªå…¸å‹ä¾‹å­æ˜¯GShard1æ¨¡å‹ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºMoEçš„å¤§è§„æ¨¡Transformeræ¨¡å‹ï¼Œå®ƒå°†ä¸€éƒ¨åˆ†ä¸“å®¶å¤åˆ¶åˆ°æ¯ä¸ªæœ¬åœ°è®¾å¤‡ä¸Šï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒå’Œæ¨ç†ã€‚

cold_expert_input = self.stride_slice_dp(cold_expert_input, (0, 0, 0, 0),
                                        (self.expert_dim, self.dp_group, cold_expert_capacity, self.hidden_size),
                                        (1, 1, 1, 1))
ä¸ºäº†æŠŠè¶…å‡ºçš„èˆå¼ƒæŠŠ

 if self.cold_hot_expert:
 #æœ€ç»ˆçš„inputshapeæ˜¯[num,dp,cap,h]
            hot_expert_input = self.gather(expert_input, Tensor(self.hot_expert_index, mstype.int32), 0)    [hotnum,dp,cap,h]
            cold_expert_input = expert_input    [num,dp,cap,h]
            cold_expert_capacity = int(expert_capacity*self.cold_token_percent)
            hot_expert_input = self.transpose_4dim_dp(hot_expert_input, (2, 0, 1, 3))
            cold_expert_input = self.transpose_4dim_dp(cold_expert_input, (0, 2, 1, 3))
            cold_expert_input = self.stride_slice_dp(cold_expert_input, (0, 0, 0, 0),
                                        (self.expert_dim, self.dp_group, cold_expert_capacity, self.hidden_size),
                                        (1, 1, 1, 1))
            # expert_output's shape: (self.dp_group, self.hidden_size, self.expert_dim, expert_capacity)
            if self.comp_comm_parallel:
                cold_expert_output = self.ffn_parallel_infer(cold_expert_input, cold_expert_capacity)
            else:
                cold_expert_output = self.ffn_infer(cold_expert_input, cold_expert_capacity)

            hot_expert_input = self.reshape(hot_expert_input, 
                                            (self.hot_expert_num * self.dp_group * expert_capacity, self.hidden_size))
            [hotnum*dp*cap,h]
            hot_expert_output = self.mlp(hot_expert_input)

            hot_expert_output = self.reshape(hot_expert_output, 
                                                (self.dp_group, self.hot_expert_num, expert_capacity, self.hidden_size))
            [dp,hotnum,cap,h]
            cold_expert_output = self.gather2(cold_expert_output, self.cold_expert_index, 1)
            if(self.cold_token_percent < 1.0):
                zeros = self.zeros((self.dp_group, self.cold_expert_num, expert_capacity-cold_expert_capacity, 
                                    self.hidden_size), mstype.float16)
                cold_expert_output = self.concat2((cold_expert_output, zeros))
            expert_output = self.concat((hot_expert_output, cold_expert_output))
            [dp,num,cap,h]
            expert_index = self.concat0((Tensor(self.hot_expert_index, mstype.int32), 
                                        self.cast(self.cold_expert_index, mstype.int32)))
            _, expert_gather_index = self.reshape(expert_index, (1,-1)).topk(self.expert_dim, largest=False)
            expert_gather_index = self.reshape(expert_gather_index,(-1,))
            expert_output = self.gather2(expert_output, expert_gather_index, 1)
            []

            expert_output = self.transpose_1dim_dp(expert_output, (0, 3, 1, 2))


    æ‚¨å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æ‚¨çš„æ¶ˆæ¯çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªPyTorchçš„ä»£ç ç‰‡æ®µã€‚æ ¹æ®æˆ‘ä»ç½‘ç»œä¸Šæœç´¢åˆ°çš„ç»“æœ ï¼Œè¿™ä¸ªä»£ç ç‰‡æ®µæ˜¯ç”¨äºå®ç°æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMixture of Experts, MoEï¼‰çš„ä¸€éƒ¨åˆ†ã€‚MoEæ˜¯ä¸€ç§åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå®ƒå°†è¾“å…¥æ•°æ®åˆ†é…ç»™ä¸åŒçš„ä¸“å®¶ç½‘ç»œï¼Œç„¶åå°†å®ƒä»¬çš„è¾“å‡ºåŠ æƒç»„åˆã€‚

è¿™ä¸ªä»£ç ç‰‡æ®µçš„æ‰§è¡Œè¿‡ç¨‹å¤§è‡´å¦‚ä¸‹ï¼š

é¦–å…ˆï¼Œå®šä¹‰ä¸€ä¸ªgateç½‘ç»œï¼Œå®ƒçš„ä½œç”¨æ˜¯æ ¹æ®è¾“å…¥xçš„ç‰¹å¾ï¼Œä¸ºæ¯ä¸ªä¸“å®¶ç½‘ç»œåˆ†é…ä¸€ä¸ªå¾—åˆ†ã€‚gateç½‘ç»œçš„è¾“å‡ºæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(batch_size, num_experts)çš„å¼ é‡ï¼Œå…¶ä¸­num_expertsæ˜¯ä¸“å®¶ç½‘ç»œçš„æ•°é‡ã€‚
ç„¶åï¼Œä½¿ç”¨torch.topkå‡½æ•°ï¼Œä»gateç½‘ç»œçš„è¾“å‡ºä¸­é€‰å‡ºæ¯ä¸ªè¾“å…¥å¯¹åº”çš„num_experts_per_tokenä¸ªæœ€é«˜å¾—åˆ†çš„ä¸“å®¶ç½‘ç»œï¼Œä»¥åŠå®ƒä»¬çš„ç´¢å¼•ã€‚expert_weightsæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(batch_size, num_experts_per_token)çš„å¼ é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªè¾“å…¥å¯¹åº”çš„ä¸“å®¶ç½‘ç»œçš„å¾—åˆ†ã€‚expert_indicesæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(batch_size, num_experts_per_token)çš„å¼ é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªè¾“å…¥å¯¹åº”çš„ä¸“å®¶ç½‘ç»œçš„ç´¢å¼•ã€‚
æ¥ç€ï¼Œå°†expert_indiceså±•å¹³ä¸ºä¸€ä¸ªä¸€ç»´å¼ é‡flat_expert_indicesï¼Œå®ƒçš„é•¿åº¦ä¸ºbatch_size * num_experts_per_tokenã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†æ–¹ä¾¿åç»­çš„ç´¢å¼•æ“ä½œã€‚
ç„¶åï¼Œå°†è¾“å…¥xæ²¿ç€ç¬¬ä¸€ä¸ªç»´åº¦é‡å¤num_experts_per_tokenæ¬¡ï¼Œä½¿å¾—å®ƒçš„å½¢çŠ¶å˜ä¸º(batch_size * num_experts_per_token, x.shape[-1])ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†è®©æ¯ä¸ªè¾“å…¥éƒ½èƒ½è¢«åˆ†é…ç»™num_experts_per_tokenä¸ªä¸“å®¶ç½‘ç»œã€‚
æœ€åï¼Œä½¿ç”¨flat_expert_indiceså¯¹xè¿›è¡Œç´¢å¼•ï¼Œå¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸º(batch_size * num_experts_per_token, x.shape[-1])çš„å¼ é‡ï¼Œå…¶ä¸­æ¯ä¸€è¡Œå¯¹åº”äºä¸€ä¸ªè¾“å…¥å’Œä¸€ä¸ªä¸“å®¶ç½‘ç»œçš„ç»„åˆã€‚ç„¶åï¼Œå°†è¿™ä¸ªå¼ é‡ä½œä¸ºè¾“å…¥ä¼ é€’ç»™å¯¹åº”çš„ä¸“å®¶ç½‘ç»œexpertï¼Œå¹¶å°†è¾“å‡ºèµ‹å€¼ç»™yã€‚yæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(batch_size * num_experts_per_token, output_size)çš„å¼ é‡ï¼Œå…¶ä¸­output_sizeæ˜¯ä¸“å®¶ç½‘ç»œçš„è¾“å‡ºç»´åº¦ã€‚
ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾batch_sizeä¸º2ï¼Œnum_expertsä¸º4ï¼Œnum_experts_per_tokenä¸º2ï¼Œx.shape[-1]ä¸º3ï¼Œoutput_sizeä¸º2ï¼Œé‚£ä¹ˆï¼š

gateç½‘ç»œçš„è¾“å‡ºå¯èƒ½æ˜¯[[0.1, 0.2, 0.3, 0.4], [0.5, 0.4, 0.3, 0.2]]ï¼Œè¡¨ç¤ºç¬¬ä¸€ä¸ªè¾“å…¥å¯¹åº”çš„ä¸“å®¶ç½‘ç»œçš„å¾—åˆ†åˆ†åˆ«ä¸º0.1, 0.2, 0.3, 0.4ï¼Œç¬¬äºŒä¸ªè¾“å…¥å¯¹åº”çš„ä¸“å®¶ç½‘ç»œçš„å¾—åˆ†åˆ†åˆ«ä¸º0.5, 0.4, 0.3, 0.2ã€‚
ä½¿ç”¨torch.topkå‡½æ•°ï¼Œå¾—åˆ°expert_weightsä¸º[[0.4, 0.3], [0.5, 0.4]]ï¼Œexpert_indicesä¸º[[3, 2], [0, 1]]ï¼Œè¡¨ç¤ºç¬¬ä¸€ä¸ªè¾“å…¥å¯¹åº”çš„æœ€é«˜å¾—åˆ†çš„ä¸“å®¶ç½‘ç»œä¸º3å’Œ2ï¼Œç¬¬äºŒä¸ªè¾“å…¥å¯¹åº”çš„æœ€é«˜å¾—åˆ†çš„ä¸“å®¶ç½‘ç»œä¸º0å’Œ1ã€‚
å°†expert_indiceså±•å¹³ï¼Œå¾—åˆ°flat_expert_indicesä¸º[3, 2, 0, 1]ã€‚
å°†è¾“å…¥xé‡å¤ï¼Œå‡è®¾xä¸º[[1, 2, 3], [4, 5, 6]]ï¼Œé‚£ä¹ˆé‡å¤åçš„xä¸º[[1, 2, 3], [1, 2, 3], [4, 5, 6], [4, 5, 6]]ã€‚
ä½¿ç”¨flat_expert_indiceså¯¹xè¿›è¡Œç´¢å¼•ï¼Œå¾—åˆ°[[4, 5, 6], [1, 2, 3], [1, 2, 3], [4, 5, 6]]ï¼Œå…¶ä¸­ç¬¬ä¸€è¡Œå¯¹åº”äºç¬¬ä¸€ä¸ªè¾“å…¥å’Œç¬¬ä¸‰ä¸ªä¸“å®¶ç½‘ç»œçš„ç»„åˆï¼Œç¬¬äºŒè¡Œå¯¹åº”äºç¬¬ä¸€ä¸ªè¾“å…¥å’Œç¬¬äºŒä¸ªä¸“å®¶ç½‘ç»œçš„ç»„åˆï¼Œç¬¬ä¸‰è¡Œå¯¹åº”äºç¬¬äºŒä¸ªè¾“å…¥å’Œç¬¬é›¶ä¸ªä¸“å®¶ç½‘ç»œçš„ç»„åˆï¼Œç¬¬å››è¡Œå¯¹åº”äºç¬¬äºŒä¸ªè¾“å…¥å’Œç¬¬ä¸€ä¸ªä¸“å®¶ç½‘ç»œçš„ç»„åˆã€‚
å°†è¿™ä¸ªå¼ é‡ä½œä¸ºè¾“å…¥ä¼ é€’ç»™å¯¹åº”çš„ä¸“å®¶ç½‘ç»œexpertï¼Œå¹¶å°†è¾“å‡ºèµ‹å€¼ç»™yã€‚å‡è®¾expertç½‘ç»œçš„è¾“å‡ºä¸º[[7, 8], [9, 10], [11, 12], [13, 14]]ï¼Œé‚£ä¹ˆyä¸º[[7, 8], [9, 10], [11, 12], [13, 14]]ã€‚
å¸Œæœ›è¿™ä¸ªä¾‹å­èƒ½å¸®åŠ©æ‚¨ç†è§£è¿™ä¸ªä»£ç ç‰‡æ®µçš„æ‰§è¡Œè¿‡ç¨‹ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿ç»§ç»­æé—®ã€‚ğŸ˜Š


é—®é¢˜ï¼š
æœ¬åœ°çƒ­é—¨ä¸“å®¶æ˜¯æŒ‡åŒä¸ªGPUä¸‹è¿˜æ˜¯åŒä¸ªæœºå™¨ä¸‹
 cold_expert_input = self.stride_slice_dp(cold_expert_input, (0, 0, 0, 0),
                                        (self.expert_dim, self.dp_group, cold_expert_capacity, self.hidden_size),
                                        (1, 1, 1, 1))
å‡½æ•°çš„ä½œç”¨ï¼Œæˆ‘çš„ç†è§£æ˜¯ï¼ŒæŠŠè¶…è¿‡è¿™ä¸ªå¤§å°çš„éƒ¨åˆ†èˆå¼ƒ
 cold_expert_output = self.ffn_infer(cold_expert_input, cold_expert_capacity)
 ä¸æ˜¯ç›¸å½“äºå·²ç»å¾—åˆ°å…¨éƒ¨çš„è¾“å‡º äº†å—ä¸ºä»€ä¹ˆè¿˜éœ€è¦åé¢å†ç”¨æœ¬åœ°çš„çƒ­é—¨ä¸“å®¶
 ç„¶åå°±æ˜¯æ€ä¹ˆæ ¹æ®expert_indicesçš„å¾—åˆ°expert_inputï¼Œ[num,...]è¿™æ ·åé¢æ‰èƒ½æ ¹æ®ä¸“å®¶indexå¾—åˆ°ç›¸åº”çš„è¾“å…¥è¾“å‡º
 mixtralkitæ˜¯ç”¨ y[expert_indices == i] = expert(x[expert_indices == i])æ–¹å¼ä¼ å…¥å¯¹åº”è¾“å…¥çš„ï¼Œè¿™æ ·æˆ‘å¾—ä¸åˆ°çƒ­é—¨ä¸“å®¶çš„è¾“å…¥ï¼Œæˆ–è€…çƒ­é—¨ä¸“å®¶çš„è¾“å‡ºä¸çŸ¥é“æ€ä¹ˆå’Œå†·é—¨çš„åˆä¸Š
 expert_weights, expert_indices = torch.topk(
            scores, self.num_experts_per_tok, dim=-1)

vim mixtral-8x7b-32kseqlen/params.json
cd MixtralKit-main
vim mixtralkit/layers/fastmoe.py
torchrun --standalone --nproc_per_node=4  tools/example.py -m ./ckpts -t ckpts/tokenizer.model
FMOE_FASTER_SCHEDULE_ENABLE=1 FMOE_FASTER_SHADOW_ENABLE=1 FMOE_FASTER_GROUP_SIZE=4 torchrun --standalone --nproc_per_node=4  tools/example.py -m ./ckpts -t ckpts/tokenizer.model


tensor([[0, 1],
        [3, 1],
        [2, 0],
        [1, 3],
        [2, 3],
        [0, 1],
        [2, 1],
        [3, 1],
        [3, 0],
        [2, 1],
        [0, 1],
        [2, 1],
        [2, 0],
        [1, 3],
        [0, 3]])

        None
(Pdb) n
> /opt/conda/lib/python3.8/site-packages/fastmoe-1.1.0-py3.8-linux-x86_64.egg/fmoe/fastermoe/shadow_policy.py(28)global_policy()
-> all_global_expert_count = torch.stack(agecs)
(Pdb) n
> /opt/conda/lib/python3.8/site-packages/fastmoe-1.1.0-py3.8-linux-x86_64.egg/fmoe/fastermoe/shadow_policy.py(31)global_policy()
-> data_size = 4
(Pdb) p all_global_expert_count
tensor([[ 7, 10,  6,  7]])

(Pdb) p moe_group
None
(Pdb) n
> /opt/conda/lib/python3.8/site-packages/fastmoe-1.1.0-py3.8-linux-x86_64.egg/fmoe/fastermoe/shadow_policy.py(28)global_policy()
-> all_global_expert_count = torch.stack(agecs)
(Pdb) n
> /opt/conda/lib/python3.8/site-packages/fastmoe-1.1.0-py3.8-linux-x86_64.egg/fmoe/fastermoe/shadow_policy.py(31)global_policy()
-> data_size = 4
(Pdb) p all_global_expert_count
tensor([[ 7, 10,  6,  7]])
(Pdb) n
> /opt/conda/lib/python3.8/site-packages/fastmoe-1.1.0-py3.8-linux-x86_64.egg/fmoe/fastermoe/shadow_policy.py(33)global_policy()
-> fwd_expert_counts = all_global_expert_count.sum(1).cpu()
(Pdb) n
> /opt/conda/lib/python3.8/site-packages/fastmoe-1.1.0-py3.8-linux-x86_64.egg/fmoe/fastermoe/shadow_policy.py(34)global_policy()
-> B_ws, indices = fwd_expert_counts.flatten().sort(0, descending=True)
(Pdb) p fwd_expert_counts
tensor([30], device='cpu')

agecsæ˜¯ä¸€ä¸ªtensoråˆ—è¡¨é•¿åº¦ä¸ºworldsize